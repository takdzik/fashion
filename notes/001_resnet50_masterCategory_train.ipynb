{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA jest niedostępna. Trening będzie przeprowadzony na CPU.\n"
     ]
    }
   ],
   "source": [
    "# Sprawdzenie dostępności GPU i CUDA\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Włącz GPU dla TensorFlow\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print(f\"CUDA jest dostępna! Używam GPU: {gpus[0].name}\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Wystąpił problem z konfiguracją GPU: {e}\")\n",
    "else:\n",
    "    print(\"CUDA jest niedostępna. Trening będzie przeprowadzony na CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wczytano ścieżki:\n",
      "Train File: C:\\studia\\wejherowo_tree\\fashion\\data\\styles_train.csv\n",
      "Dataset Path: C:\\Users\\tthaddey\\.cache\\kagglehub\\datasets\\paramaggarwal\\fashion-product-images-small\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "# Wczytywanie ścieżek z config.json\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "config_path = Path(\"../config.json\")\n",
    "with open(config_path, \"r\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "train_file = Path(config[\"train_file\"])\n",
    "dataset_path = Path(config[\"dataset_path\"])\n",
    "\n",
    "print(f\"Wczytano ścieżki:\\nTrain File: {train_file}\\nDataset Path: {dataset_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pierwsze wiersze zbioru treningowego:\n",
      "      id gender masterCategory subCategory articleType baseColour  season  \\\n",
      "0  58770    men        apparel     topwear      shirts       grey  summer   \n",
      "1  31286    men        apparel     topwear     tshirts      white  summer   \n",
      "2  27277  women        apparel     topwear      kurtas      green    fall   \n",
      "3  13251    men        apparel  bottomwear       other      beige    fall   \n",
      "4  36253    men        apparel       other       other  navy blue  summer   \n",
      "\n",
      "     year   usage                            productDisplayName  \\\n",
      "0  2012.0  casual                     locomotive men grey shirt   \n",
      "1  2012.0  casual                        puma men white t-shirt   \n",
      "2  2011.0  ethnic                 mother earth women blue kurta   \n",
      "3  2011.0  casual       palm tree kids boy solid beige trousers   \n",
      "4  2016.0  casual  sdl by sweet dreams men navy blue pyjama set   \n",
      "\n",
      "                                          image_path  \n",
      "0  C:\\Users\\tthaddey\\.cache\\kagglehub\\datasets\\pa...  \n",
      "1  C:\\Users\\tthaddey\\.cache\\kagglehub\\datasets\\pa...  \n",
      "2  C:\\Users\\tthaddey\\.cache\\kagglehub\\datasets\\pa...  \n",
      "3  C:\\Users\\tthaddey\\.cache\\kagglehub\\datasets\\pa...  \n",
      "4  C:\\Users\\tthaddey\\.cache\\kagglehub\\datasets\\pa...  \n",
      "Łączna liczba próbek: 35261\n"
     ]
    }
   ],
   "source": [
    "# Wczytywanie zbioru treningowego\n",
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(train_file)\n",
    "\n",
    "# Tworzenie pełnych ścieżek do obrazów\n",
    "# Konwersja każdej ścieżki na obiekt Path\n",
    "df_train[\"image_path\"] = df_train[\"id\"].apply(lambda x: dataset_path / \"images\" / f\"{x}.jpg\")\n",
    "\n",
    "\n",
    "# Sprawdzenie danych\n",
    "print(\"Pierwsze wiersze zbioru treningowego:\")\n",
    "print(df_train.head())\n",
    "print(f\"Łączna liczba próbek: {len(df_train)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ustawienia dla generatora danych\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_size = (224, 224)  # Rozmiar obrazu zgodny z wejściem ResNet18\n",
    "batch_size = 32\n",
    "\n",
    "# Funkcja pomocnicza do ładowania obrazów\n",
    "def preprocess_image(image_path, label):\n",
    "    # Wczytanie i przeskalowanie obrazu\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, image_size)\n",
    "    image = image / 255.0  # Normalizacja do zakresu [0, 1]\n",
    "    return image, label\n",
    "\n",
    "# Przygotowanie etykiet\n",
    "categories = df_train[\"masterCategory\"].unique()\n",
    "category_to_index = {category: idx for idx, category in enumerate(categories)}\n",
    "df_train[\"category_index\"] = df_train[\"masterCategory\"].map(category_to_index)\n",
    "\n",
    "# Konwersja do TensorFlow Dataset\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (df_train[\"image_path\"].astype(str), df_train[\"category_index\"])\n",
    ")\n",
    "train_ds = train_ds.map(preprocess_image).shuffle(1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,799</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m524,544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │         \u001b[38;5;34m1,799\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,114,055</span> (91.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,114,055\u001b[0m (91.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">526,343</span> (2.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m526,343\u001b[0m (2.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Wczytanie pretrenowanego modelu ResNet50\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Zamrożenie warstw\n",
    "\n",
    "# Dodanie warstw własnych\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(categories), activation=\"softmax\")  # Liczba klas zgodna z masterCategory\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Sprawdzenie folderu zapisu modelu\n",
    "models_dir = Path(\"../models\")\n",
    "models_dir.mkdir(parents=True, exist_ok=True)  # Tworzy katalog, jeśli nie istnieje\n",
    "\n",
    "# Trening modelu\n",
    "epochs = 10\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapis modelu do folderu ../models/\n",
    "model_save_path = models_dir / \"resnet18_masterCategory_model.h5\"\n",
    "model.save(model_save_path)\n",
    "print(f\"Model został zapisany w: {model_save_path}\")\n",
    "\n",
    "# Aktualizacja pliku config.json\n",
    "config_path = Path(\"../config.json\")\n",
    "if config_path.exists():\n",
    "    with open(config_path, \"r\") as config_file:\n",
    "        config = json.load(config_file)\n",
    "else:\n",
    "    config = {}\n",
    "\n",
    "config[\"resnet18_masterCategory_model\"] = str(model_save_path.resolve())\n",
    "\n",
    "with open(config_path, \"w\") as config_file:\n",
    "    json.dump(config, config_file, indent=4)\n",
    "\n",
    "print(f\"Plik konfiguracyjny zaktualizowany: {config_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
